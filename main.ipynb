{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install paddleocr groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO   ] [Logger      ] Record log in C:\\Users\\admin\\.kivy\\logs\\kivy_25-02-28_4.txt\n",
      "[INFO   ] [deps        ] Successfully imported \"kivy_deps.angle\" 0.4.0\n",
      "[INFO   ] [deps        ] Successfully imported \"kivy_deps.glew\" 0.3.1\n",
      "[INFO   ] [deps        ] Successfully imported \"kivy_deps.sdl2\" 0.8.0\n",
      "[INFO   ] [Kivy        ] v2.3.1\n",
      "[INFO   ] [Kivy        ] Installed at \"c:\\Users\\admin\\Desktop\\New folder\\test\\lib\\site-packages\\kivy\\__init__.py\"\n",
      "[INFO   ] [Python      ] v3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]\n",
      "[INFO   ] [Python      ] Interpreter at \"c:\\Users\\admin\\Desktop\\New folder\\test\\Scripts\\python.exe\"\n",
      "[INFO   ] [Logger      ] Purge log fired. Processing...\n",
      "[INFO   ] [Logger      ] Purge finished!\n",
      "[INFO   ] [Factory     ] 195 symbols loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO   ] [Image       ] Providers: img_tex, img_dds, img_sdl2, img_pil (img_ffpyplayer ignored)\n",
      "[INFO   ] [Text        ] Provider: sdl2\n",
      "[INFO   ] [Window      ] Provider: sdl2\n",
      "[INFO   ] [GL          ] Using the \"OpenGL\" graphics system\n",
      "[INFO   ] [GL          ] GLEW initialization succeeded\n",
      "[INFO   ] [GL          ] Backend used <glew>\n",
      "[INFO   ] [GL          ] OpenGL version <b'4.6.0 NVIDIA 566.07'>\n",
      "[INFO   ] [GL          ] OpenGL vendor <b'NVIDIA Corporation'>\n",
      "[INFO   ] [GL          ] OpenGL renderer <b'NVIDIA GeForce RTX 3060/PCIe/SSE2'>\n",
      "[INFO   ] [GL          ] OpenGL parsed version: 4, 6\n",
      "[INFO   ] [GL          ] Shading version <b'4.60 NVIDIA'>\n",
      "[INFO   ] [GL          ] Texture max size <32768>\n",
      "[INFO   ] [GL          ] Texture max units <32>\n",
      "[INFO   ] [Window      ] auto add sdl2 input provider\n",
      "[INFO   ] [Window      ] virtual keyboard not allowed, single mode, not docked\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/02/28 15:15:47] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='C:\\\\Users\\\\admin/.paddleocr/whl\\\\det\\\\en\\\\en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='C:\\\\Users\\\\admin/.paddleocr/whl\\\\rec\\\\en\\\\en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='c:\\\\Users\\\\admin\\\\Desktop\\\\New folder\\\\test\\\\lib\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='C:\\\\Users\\\\admin/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "source code not available",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 176\u001b[0m\n\u001b[0;32m    173\u001b[0m         popup\u001b[38;5;241m.\u001b[39mopen()\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 176\u001b[0m     \u001b[43mNutritionalApp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\admin\\Desktop\\New folder\\test\\lib\\site-packages\\kivy\\app.py:955\u001b[0m, in \u001b[0;36mApp.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    952\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    953\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Launches the app in standalone mode.\u001b[39;00m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m--> 955\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_prepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    956\u001b[0m     runTouchApp()\n\u001b[0;32m    957\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "File \u001b[1;32mc:\\Users\\admin\\Desktop\\New folder\\test\\lib\\site-packages\\kivy\\app.py:924\u001b[0m, in \u001b[0;36mApp._run_prepare\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[0;32m    923\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_config()\n\u001b[1;32m--> 924\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_kv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkv_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    925\u001b[0m     root \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild()\n\u001b[0;32m    926\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m root:\n",
      "File \u001b[1;32mc:\\Users\\admin\\Desktop\\New folder\\test\\lib\\site-packages\\kivy\\app.py:677\u001b[0m, in \u001b[0;36mApp.load_kv\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 677\u001b[0m         default_kv_directory \u001b[38;5;241m=\u001b[39m dirname(\u001b[43mgetfile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    678\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m default_kv_directory \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    679\u001b[0m             default_kv_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\inspect.py:785\u001b[0m, in \u001b[0;36mgetfile\u001b[1;34m(object)\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__file__\u001b[39m\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 785\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource code not available\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m is a built-in class\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mobject\u001b[39m))\n\u001b[0;32m    787\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ismethod(\u001b[38;5;28mobject\u001b[39m):\n",
      "\u001b[1;31mOSError\u001b[0m: source code not available"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "from flask import Flask, request, render_template, jsonify\n",
    "from groq import Groq\n",
    "from paddleocr import PaddleOCR\n",
    "import csv\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Initialize OCR and Groq\n",
    "try:\n",
    "    ocr = PaddleOCR(use_angle_cls=True, lang='en')\n",
    "    logging.info(\"PaddleOCR initialized successfully\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Failed to initialize PaddleOCR: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    client = Groq(api_key=\"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\")\n",
    "    logging.info(\"Groq client initialized successfully\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Failed to initialize Groq client: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Global variables\n",
    "image_path = None\n",
    "csv_path = 'data.csv'\n",
    "log_csv_path = 'refined_text_log.csv'\n",
    "\n",
    "# Original logic functions (unchanged)\n",
    "def log_refined_text(refined_text):\n",
    "    \"\"\"\n",
    "    Logs the refined OCR-extracted text into a CSV file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(log_csv_path, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([refined_text])\n",
    "        logging.debug(f\"Logged refined text to {log_csv_path}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error logging refined text: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def extract_and_clean_text(image_path):\n",
    "    \"\"\"\n",
    "    Extracts text from an image using OCR and cleans it.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logging.debug(f\"Processing image with OCR: {image_path}\")\n",
    "        results = ocr.ocr(image_path, cls=True)\n",
    "        if not results or not results[0]:\n",
    "            logging.warning(f\"No text detected in image: {image_path}\")\n",
    "            raise ValueError(\"No readable text detected in the image\")\n",
    "        logging.debug(f\"OCR results: {results}\")\n",
    "        cleaned_text = []\n",
    "        for line in results[0]:\n",
    "            text = line[1][0]\n",
    "            if len(text) >= 3 and text.isprintable():\n",
    "                cleaned_text.append(text)\n",
    "        logging.debug(f\"Cleaned text: {cleaned_text}\")\n",
    "        return cleaned_text\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in extract_and_clean_text: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def process_image_and_csv(image_path, csv_path):\n",
    "    \"\"\"\n",
    "    Processes a nutritional image, sending data to the Groq API for analysis.\n",
    "    \"\"\"\n",
    "    if not image_path:\n",
    "        logging.error(\"No image path provided\")\n",
    "        return \"Error: No image path provided!\", \"\", \"\"\n",
    "    try:\n",
    "        cleaned_text = extract_and_clean_text(image_path)\n",
    "        extracted_text = \", \".join(cleaned_text)\n",
    "        logging.debug(f\"Extracted text: {extracted_text}\")\n",
    "        prompt = f\"\"\"\n",
    "        I am using OCR to extract the Nutritional information from the Food pack labels. \n",
    "        I need you to refine the text: {extracted_text}. Just return the nutritional facts and Ingredients. \n",
    "        Based on the ingredients, what is the Food name? No other words.\n",
    "        \"\"\"\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"llama-3.3-70b-versatile\",\n",
    "            messages=[{\"role\": \"system\", \"content\": \"You are a professional medical advisor.\"},\n",
    "                      {\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.7,\n",
    "            max_tokens=300,\n",
    "            top_p=1,\n",
    "            stream=False\n",
    "        )\n",
    "        logging.debug(f\"Groq response: {response}\")\n",
    "        refined_text = response.choices[0].message.content\n",
    "        log_refined_text(refined_text)\n",
    "        return refined_text, \"\", \"\"\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in process_image_and_csv: {str(e)}\")\n",
    "        return f\"Error occurred: {str(e)}\", \"\", \"\"\n",
    "\n",
    "# Flask setup\n",
    "UPLOAD_FOLDER = 'static/uploads'\n",
    "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
    "app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/upload_nutritional', methods=['POST'])\n",
    "def upload_nutritional():\n",
    "    global image_path\n",
    "    if 'file' not in request.files:\n",
    "        logging.error(\"No file part in request\")\n",
    "        return jsonify({\"error\": \"No file uploaded\"}), 400\n",
    "    file = request.files['file']\n",
    "    if file.filename == '':\n",
    "        logging.error(\"No file selected\")\n",
    "        return jsonify({\"error\": \"No file selected\"}), 400\n",
    "    try:\n",
    "        filepath = os.path.join(app.config['UPLOAD_FOLDER'], file.filename)\n",
    "        logging.debug(f\"Saving file to: {filepath}\")\n",
    "        file.save(filepath)\n",
    "        if not os.path.exists(filepath):\n",
    "            logging.error(\"File save failed\")\n",
    "            return jsonify({\"error\": \"Failed to save the uploaded file\"}), 500\n",
    "        image_path = filepath\n",
    "        refined_text, _, _ = process_image_and_csv(image_path, csv_path)\n",
    "        if refined_text.startswith(\"Error occurred:\"):\n",
    "            logging.error(f\"Processing failed: {refined_text}\")\n",
    "            return jsonify({\"error\": refined_text}), 500\n",
    "        logging.info(\"Nutritional image processed successfully\")\n",
    "        return jsonify({\"refined_text\": refined_text, \"image_url\": f\"/{filepath}\"})\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Upload nutritional error: {str(e)}\")\n",
    "        return jsonify({\"error\": f\"Server error: {str(e)}\"}), 500\n",
    "\n",
    "@app.route('/upload_medical', methods=['POST'])\n",
    "def upload_medical():\n",
    "    if 'file' not in request.files:\n",
    "        logging.error(\"No file part in request\")\n",
    "        return jsonify({\"error\": \"No file uploaded\"}), 400\n",
    "    file = request.files['file']\n",
    "    if file.filename == '':\n",
    "        logging.error(\"No file selected\")\n",
    "        return jsonify({\"error\": \"No file selected\"}), 400\n",
    "    try:\n",
    "        filepath = os.path.join(app.config['UPLOAD_FOLDER'], file.filename)\n",
    "        logging.debug(f\"Saving file to: {filepath}\")\n",
    "        file.save(filepath)\n",
    "        if not os.path.exists(filepath):\n",
    "            logging.error(\"File save failed\")\n",
    "            return jsonify({\"error\": \"Failed to save the uploaded file\"}), 500\n",
    "        extracted_text = extract_and_clean_text(filepath)\n",
    "        medical_prompt = f\"\"\"\n",
    "        I am using OCR to extract the text from a medical report. \n",
    "        Refine the text: {extracted_text}, remove any noise, and provide a clear summary of the medical findings. \n",
    "        Just return the important medical details and diagnosis if available, no extra words.\n",
    "        \"\"\"\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"llama-3.3-70b-versatile\",\n",
    "            messages=[{\"role\": \"system\", \"content\": \"You are a professional medical advisor.\"},\n",
    "                      {\"role\": \"user\", \"content\": medical_prompt}],\n",
    "            temperature=0.7,\n",
    "            max_tokens=300,\n",
    "            top_p=1,\n",
    "            stream=False\n",
    "        )\n",
    "        logging.info(\"Medical report processed successfully\")\n",
    "        return jsonify({\"refined_text\": response.choices[0].message.content})\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Upload medical error: {str(e)}\")\n",
    "        return jsonify({\"error\": f\"Server error: {str(e)}\"}), 500\n",
    "\n",
    "@app.route('/evaluate_combined', methods=['POST'])\n",
    "def evaluate_combined():\n",
    "    data = request.json\n",
    "    nutritional_text = data.get('nutritional_text', '').strip()\n",
    "    medical_text = data.get('medical_text', '').strip()\n",
    "    selected_model = data.get('model', 'llama-3.3-70b-versatile')\n",
    "    selected_language = data.get('language', 'English')\n",
    "\n",
    "    if not nutritional_text:\n",
    "        logging.error(\"No nutritional text provided\")\n",
    "        return jsonify({\"error\": \"Please analyze nutritional data first\"}), 400\n",
    "    if not medical_text:\n",
    "        logging.error(\"No medical text provided\")\n",
    "        return jsonify({\"error\": \"Please process medical report first\"}), 400\n",
    "\n",
    "    try:\n",
    "        next_prompt = f\"\"\"\n",
    "        Dear User,\n",
    "\n",
    "        Based on the extracted text from your food pack labels: {nutritional_text},\n",
    "        and the details from your medical report: {medical_text},\n",
    "        please evaluate the ingredients for safety.\n",
    "        Provide a short recommendation on whether the food is safe to consume,\n",
    "        including the safe quantity for intake if applicable.\n",
    "        If the food is not recommended, briefly explain why it should be avoided.\n",
    "\n",
    "        Please provide the response in the following format:\n",
    "\n",
    "        1. First, a short and clear recommendation in **English**.\n",
    "        2. After that, a short and clear recommendation in **{selected_language}** that corresponds to the English response.\n",
    "        \"\"\"\n",
    "        final_response = client.chat.completions.create(\n",
    "            model=selected_model,\n",
    "            messages=[{\"role\": \"system\", \"content\": \"You are a professional medical advisor.\"},\n",
    "                      {\"role\": \"user\", \"content\": next_prompt}],\n",
    "            temperature=0.7,\n",
    "            max_tokens=400,\n",
    "            top_p=1,\n",
    "            stream=False\n",
    "        )\n",
    "        logging.info(\"Combined evaluation completed successfully\")\n",
    "        return jsonify({\"result\": final_response.choices[0].message.content})\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Evaluate combined error: {str(e)}\")\n",
    "        return jsonify({\"error\": f\"Server error: {str(e)}\"}), 500\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
    "        logging.info(f\"Upload folder created/verified: {UPLOAD_FOLDER}\")\n",
    "        app.run(debug=True)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Startup error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Flask\n",
      "  Downloading flask-3.1.0-py3-none-any.whl (102 kB)\n",
      "     ---------------------------------------- 0.0/103.0 kB ? eta -:--:--\n",
      "     --- ------------------------------------ 10.2/103.0 kB ? eta -:--:--\n",
      "     ------- ----------------------------- 20.5/103.0 kB 162.5 kB/s eta 0:00:01\n",
      "     ------------------ ------------------ 51.2/103.0 kB 327.7 kB/s eta 0:00:01\n",
      "     ------------------------------------ 103.0/103.0 kB 539.2 kB/s eta 0:00:00\n",
      "Collecting click>=8.1.3\n",
      "  Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "     ---------------------------------------- 0.0/98.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 98.2/98.2 kB 1.9 MB/s eta 0:00:00\n",
      "Collecting Werkzeug>=3.1\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "     ---------------------------------------- 0.0/224.5 kB ? eta -:--:--\n",
      "     ------- ------------------------------- 41.0/224.5 kB 1.9 MB/s eta 0:00:01\n",
      "     ------- ------------------------------- 41.0/224.5 kB 1.9 MB/s eta 0:00:01\n",
      "     ------------------ ----------------- 112.6/224.5 kB 819.2 kB/s eta 0:00:01\n",
      "     -------------------------------------- 224.5/224.5 kB 1.1 MB/s eta 0:00:00\n",
      "Collecting Jinja2>=3.1.2\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "     ---------------------------------------- 0.0/134.9 kB ? eta -:--:--\n",
      "     -------------------- ------------------ 71.7/134.9 kB 1.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 134.9/134.9 kB 1.6 MB/s eta 0:00:00\n",
      "Collecting blinker>=1.9\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Collecting itsdangerous>=2.2\n",
      "  Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\desktop\\new folder\\test\\lib\\site-packages (from click>=8.1.3->Flask) (0.4.6)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)\n",
      "Installing collected packages: MarkupSafe, itsdangerous, click, blinker, Werkzeug, Jinja2, Flask\n",
      "Successfully installed Flask-3.1.0 Jinja2-3.1.6 MarkupSafe-3.0.2 Werkzeug-3.1.3 blinker-1.9.0 click-8.1.8 itsdangerous-2.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
